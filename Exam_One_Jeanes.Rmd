---
title: "Exam_One_A"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```





# Terminology
1. What is the difference between a *population* and a *sample*?

Answer: 


2. What is the difference between a *statistic* and a *parameter*.  Give an example of a *statistic*.

Answer:


3. In a data set, what is the difference between an *observation* and a *variable*?

Answer:



# Exploratory Data Analysis

Use one of the following two chunks to load the data set `Alelager`.

If you have the `resampledata` package installed use:

```{r}
library(resampledata)
BeerData<-Alelager
head(BeerData)
```

**or**, you can use:

```{r}
BeerData<-read.csv("https://sites.google.com/site/chiharahesterberg/data2/Alelager.csv")
head(BeerData)
```

1. Create side-by-side box plots of the alcohol content, grouped by beer type. Comment on the information the box plots convey.

```{r}

```

Commentary: 


2. Create a histogram of the calorie content of all beers in the data set. Describe the distribution.
```{r}

```

Description of distribution:

3.  Sampling Distribution
*	Simulate the sampling distribution of the mean of the number of calories, for samples of size 3.
		
```{r}

```



*	Create a histogram and describe the simulated sampling distribution.
		
```{r}

```


Description of sampling distribution:		
		
*	Use the simulation to find the probability that the average calorie content of 3 beers is less than 150 calories.
		
```{r}
```
		
* Use the simulation to find the probability that the average calorie content of 3 beers is more than 160 calories.
  
```{r}
```
  
  
4. The following code generates two ecdfs, one for calories of ales, one for calories of lagers. 
 
```{r}
Ales <- subset(BeerData, select=Calories, subset=Type=="Ale", drop=T)
Lagers <- subset(BeerData, select=Calories, subset=Type=="Lager", drop=T)
#plot.new()
plot.ecdf(Ales, col="red")
plot.ecdf(Lagers, col="blue", add=TRUE)
abline(v=165)
```

What percentage of ales in the data set have less than 165 calories? 

What percentage of lagers in the data set have less than 165 calories?


# Permutation test

Conduct a permutation test to determine whether there is a difference in the mean calorie content between ales and lagers. Your test should start with a statement of the formal hypotheses and finish with a conclusion.

Put each step in its own chunk and **clearly explain what each chunk is doing and what information the output provides.**

```{r}

```




```{r}

```



```{r}

```


```{r}

```



```{r}

```


(I put in several r-chunks.  You might use more, you might use fewer.)


# Critical reading

Below, I conduct a permutation test to test whether there was, on average, a difference in the annual snow fall in Colorado in the years 2019 and 2020.  Identify the mistake and fix it.

First, we load and briefly inspect the data:
```{r}
SnowData <- read.csv("https://www.dropbox.com/s/h8lkjdqoqui3bzw/TestDownload2.csv?dl=1")
head(SnowData)
```

The data shows annual snow fall recorded at 51 NOAA weather station in Colorado in 2019, and 2020. 


The formal statements of the hypotheses are:

$$H_0: \mu_{d_{2020}-d_{2019}}=0$$

$$H_A: \mu_{d_{2020}-d_{2019}}\neq 0$$

where $d_{2020}-d_{2019}$ represents the difference in snow fall by station. 

We'll compute the difference in snowfall at each station and compute the observed mean of differences:

```{r}
DiffAtStations<-SnowData$Snow2020-SnowData$Snow2019
Observed<-mean(DiffAtStations)
Observed
```

Next, we'll pool the data in order to find a permutation distribution:

```{r}
PooledData<- c(SnowData$Snow2020, SnowData$Snow2019)
```

Here is the loop that generates a permutation distribution:


```{r}
N=10^4
SampleDist<-numeric(N)
for (i in 1:N)
{index<-sample(102,51, replace=F)
SampleDist[i]<- mean(PooledData[index]-PooledData[-index])}
```



Finally, we compute the $p$-value for our observed statistic:

```{r}
2*min((sum(SampleDist >= Observed)+1)/(N+1),
(sum(SampleDist <= Observed)+1)/(N+1))
```

Since the $p$-value is small we reject the null hypothesis and conclude that the mean difference in snow depth between 2019 and 2020 was different.



**Your notes are below.  Do NOT delete the following chunk or your file may not knit.
```{r}
knitr::knit_exit()
```



for (i in 1:3){ #Looking for 1, 2, or 3 sixes
  n<-6*i#n=6,12,18
  q<-pbinom(i-1,n,1/6)#probability <s sixes in dice
  plot(dbinom(0:i,n,1/6),type='h')#Plotting distribution of each scenario
  cat("Probability of at least",i,"six/sixes in",n,"fair dice tossed:",1-q,"\n")
}

That is, $P(X \leq -1.281552)=0.1$ is $X$ is a random variable with a standard normal distribution.

Then we do the same thing for the data. How much of data lies in the first 10% of the data, the first 20% of the data, etc.  (The data isn't continuous so we won't do this calculation, we'll let R figure it out....)  Call these answers $x_1, x_2, x_3, \dots$

Now, plot the points $(q_1, x_1), (q_2, x_2), \dots$.

The  closer these points come to being on a straight line the more *normal* the distrubution.

-----------------------
plot.new()
qqnorm(Spruce$Height5)
qqline(Spruce$Height5)
-----------------------

Remember, this is a discrete random variable, not a continuous random variable.

The usual language for binomial distributions is that one possibility (testing positive) is called a *success*, the other possibility (testing negative) is called a *failure*.  There are only *2 options*.  Other examples: it rains today (or not),  passing a statistics exam (or not), etc.

Here is the binomial distribution for this random variable:


(It's maybe a little easier to see with `type='b'`, just remember the random variable is discrete.)

plot(dbinom(0:15, 15, postest), type='h')


**Sampling Simulation**

N=10^6
Xbar <- numeric(N)
for (i in 1:N)
  {mysample <- sample(ChiMarathonMen$FinishMin, size=6,replace=F)
  Xbar[i] <- mean(mysample)}

**Resampling for permutation testing:**


alldelays<-delays$Delay
poolSz<-length(alldelays)
poolSz
group1Sz<-length(may$Delay)
group1Sz
group2Sz<-length(june$Delay)
group2Sz



n<-10^6-1
result<-numeric(n)
for(i in 1:n){
  index<-sample(poolSz,size=group1Sz,replace=F)
  result[i]<-(sum(alldelays[index]>20)/group1Sz)-(sum(alldelays[-index]>20)/group2Sz)
}







