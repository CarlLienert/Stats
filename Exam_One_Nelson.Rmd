---
title: "Exam_One_A"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```





# Terminology
1. What is the difference between a *population* and a *sample*?

Answer: 


2. What is the difference between a *statistic* and a *parameter*.  Give an example of a *statistic*.

Answer:


3. In a data set, what is the difference between an *observation* and a *variable*?

Answer:



# Exploratory Data Analysis

Use one of the following two chunks to load the data set `Alelager`.

If you have the `resampledata` package installed use:

```{r}
library(resampledata)
BeerData<-Alelager
head(BeerData)
```

**or**, you can use:

```{r}
BeerData<-read.csv("https://sites.google.com/site/chiharahesterberg/data2/Alelager.csv")
head(BeerData)
```

1. Create side-by-side box plots of the alcohol content, grouped by beer type. Comment on the information the box plots convey.

```{r}

```

Commentary: 


2. Create a histogram of the calorie content of all beers in the data set. Describe the distribution.
```{r}

```

Description of distribution:

3.  Sampling Distribution
*	Simulate the sampling distribution of the mean of the number of calories, for samples of size 3.
		
```{r}

```



*	Create a histogram and describe the simulated sampling distribution.
		
```{r}

```


Description of sampling distribution:		
		
*	Use the simulation to find the probability that the average calorie content of 3 beers is less than 150 calories.
		
```{r}
```
		
* Use the simulation to find the probability that the average calorie content of 3 beers is more than 160 calories.
  
```{r}
```
  
  
4. The following code generates two ecdfs, one for calories of ales, one for calories of lagers. 
 
```{r}
Ales <- subset(BeerData, select=Calories, subset=Type=="Ale", drop=T)
Lagers <- subset(BeerData, select=Calories, subset=Type=="Lager", drop=T)
#plot.new()
plot.ecdf(Ales, col="red")
plot.ecdf(Lagers, col="blue", add=TRUE)
abline(v=165)
```

What percentage of ales in the data set have less than 165 calories? 

What percentage of lagers in the data set have less than 165 calories?


# Permutation test

Conduct a permutation test to determine whether there is a difference in the mean calorie content between ales and lagers. Your test should start with a statement of the formal hypotheses and finish with a conclusion.

Put each step in its own chunk and **clearly explain what each chunk is doing and what information the output provides.**

```{r}

```




```{r}

```



```{r}

```


```{r}

```



```{r}

```


(I put in several r-chunks.  You might use more, you might use fewer.)


# Critical reading

Below, I conduct a permutation test to test whether there was, on average, a difference in the annual snow fall in Colorado in the years 2019 and 2020.  Identify the mistake and fix it.

First, we load and briefly inspect the data:
```{r}
SnowData <- read.csv("https://www.dropbox.com/s/h8lkjdqoqui3bzw/TestDownload2.csv?dl=1")
head(SnowData)
```

The data shows annual snow fall recorded at 51 NOAA weather station in Colorado in 2019, and 2020. 


The formal statements of the hypotheses are:

$$H_0: \mu_{d_{2020}-d_{2019}}=0$$

$$H_A: \mu_{d_{2020}-d_{2019}}\neq 0$$

where $d_{2020}-d_{2019}$ represents the difference in snow fall by station. 

We'll compute the difference in snowfall at each station and compute the observed mean of differences:

```{r}
DiffAtStations<-SnowData$Snow2020-SnowData$Snow2019
Observed<-mean(DiffAtStations)
Observed
```

Next, we'll pool the data in order to find a permutation distribution:

```{r}
PooledData<- c(SnowData$Snow2020, SnowData$Snow2019)
```

Here is the loop that generates a permutation distribution:


```{r}
N=10^4
SampleDist<-numeric(N)
for (i in 1:N)
{index<-sample(102,51, replace=F)
SampleDist[i]<- mean(PooledData[index]-PooledData[-index])}
```



Finally, we compute the $p$-value for our observed statistic:

```{r}
2*min((sum(SampleDist >= Observed)+1)/(N+1),
(sum(SampleDist <= Observed)+1)/(N+1))
```

Since the $p$-value is small we reject the null hypothesis and conclude that the mean difference in snow depth between 2019 and 2020 was different.



**Your notes are below.  Do NOT delete the following chunk or your file may not knit.
```{r}
knitr::knit_exit()
```


*Chap 1*

-A parameter is a numerical characteristic of a population or probability distribution and a statistic is a numerical characteristic of the data.
-Observational study observes the outcomes of the participants without influence and an experiment researchers will manipulate the the environment to observe the response of the subjects.

*Chap 2*
-For a histogram to display probabilities
```{r}
hist(UAOnly$Delay, freq=FALSE)
```
-Creating a subset
```{r}
#WYGirls <- subset(Girls2004, select=Weight, subset=State=="WY", drop=T)
```
-contingency tables
```{r}
#table(dataset$variable, dataset$variable)
#prop.table(table(dataset$variable, dataset$variable), (1 or 2)))
#boxplot(dataset$variable~dataset$variable, na.rm=t)
```
-ECDF's - useful for comparing TWO distributions
$$F_n(x)=\frac{\text{number of values } \leq x}{\text{sample size}}$$
```{r}
#plot.new()
#plot.ecdf(dataset$variable, col="red")
#plot.ecdf(dataset$variable, col="blue", add=true)
#abline(v=#)

```
-qqplots for normal distributions
```{r}
#qnorm(.1) (theoretical)
#plot.new()
#qqnorm(dataset$variable)
#qqline(dataset$variable)
```
-display data
```{r}
#tapply(FlightData$Delay, FlightData$Carrier, mean)
```

*Chap 3*
-matched pairs (mean of difference)
-not matched (difference of mean)
-hypothesis test is an argument that an observed, measured outcome (statistic) is significant (i.e. not fake news)
-Alternative hypothesis is a statement that there is a real effect. The data may provide convincing evidence that this hypothesis is true.
-P-value is the probability that chance alone would produce a statistic as extreme as the observed test statistic if the null hypothesis were true.

A result is statistically significant if it would rarely occur by chance.

1. suppose no proof by contradiction--H0. Null hypothesis is the status quo in the absence of data providing convincing evidence to the contrary.

2. find a distribution assuming that there is no difference in length of delays-resampling

-means of differences- matched pairs
```{r}
#DiffInPairs <- IceCream$VanillaCalories-IceCream$ChocolateCalories
#DiffInPairs
#observed <- mean(DiffInPairs)

-Create a vector 
#sample(c(-1,1), poolsize, replace=T)
-resample
#N <- 10^4-1
#result <- numeric(N)
#for (i in 1:N)
#{Sign <- sample(c(-1,1), poolsize, replace=T) #random swapping assignment
#  Diff <- Sign*DiffInPairs #compute differences within matched pairs
#result[i] <- mean(Diff) #assign the mean of the differences to the result vector
#}
```

difference of means- not matched pairs
```{r}
#UAdelays <- subset(delays, select=Delay, subset=Carrier=="UA", drop=T)
#AAdelays <- subset(delays, select=Delay, subset=Carrier=="AA", drop=T)
#observed <- mean(UAdelays)-mean(AAdelays)
#observed

#length(UAdelays)
#length(AAdelays)
#length(UAdelays)+length(AAdelays) (pool to pull samples from)

#*Resampling*
  
#N <- 10^4-1
#result <- numeric(N)
#for (i in 1:N)
#{index <- sample(4029,size=1123, replace=F)
#result[i] <- mean(alldelays[index])-mean(alldelays[-index])
#} 

```

* `N` is the number of times we'll resample
* `result` is a vector for storing the results of each resample
* the loop is each iteration of the resample

3.) observe the data (sampling of delays)
```{r}
#hist(result)
```

4.) Compare the observation to the distribution

5.) if the probability of the observed statistic is so small as to be fake news, then i must be wrong. p-value

This is for both tails
```{r}
#sum(result>=observed)
#sum(result<=observed)
```
-two sided test
```{r}
#2*min((sum(result >= observed)+1)/(N+1),
#(sum(result <= observed)+1)/(N+1))
```
```
*Chap 4*
-binomial- the codes below provide the same probablity
```{r}
#choose(12,2)*success^2*failure^10
#p or d binom(12,2, success)
```
* d-*dist* x=number
* p-*dist* which computes the area in the lower tail, i.e. (X <= x). It is the *cdf*.
* q-*dist* which computes the value $q$ such that $P(X \leq q)= \text{ the prob. you send}$
* r-*dist* which generates a random sample from the given distribution.  This is useful for running simulations

The *geometric* distribution is for a discrete random variable. (counts failures before a success)
```{r}
# probability of making a basket -basketsuccess <- 0.15
#basketfailure <- 1-basketsuccess
#dgeom(3, basketsuccess) (if a basket is made on the 4th shot)
```
resampling- tas the size of the sample increases, the distribution begins to look more normal.
```{r}
#N=10^4
#sampdist <- numeric(N)
#for (i in 1:N)
#{SampFromGeometric <- rgeom(5,basketsuccess)
#sampdist[i] <- mean(SampFromGeometric)}

#hist(sampdist, freq=F)

#mean(sampdist)
```
The *exponential* distribution is a continuous version of the *geometric* distribution. It is also a "waiting" distribution.  While geometric is the number of times you have to wait, exponential is how long you have to wait.

```{r}
#pexp(time, lambda) 
#qexp(.9,3)
```







